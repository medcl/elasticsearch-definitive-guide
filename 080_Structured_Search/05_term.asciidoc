[[_finding_exact_values]]
=== 查找精确值

当进行精确值查找时，((("structured search", "finding exact values")))((("exact values", "finding"))) 我们会使用过滤器（filters）。过滤器
因为其快而显得重要。过滤器不会计算
相关度（直接跳过了整个评分阶段）而且很容易对其缓存。我们会
在本章后面的 <<filter-caching, 过滤器缓存>> 中讨论过滤器的性能优势，
不过现在只要记住：请尽可能多的使用过滤器。

==== 过滤数字

我们首先来看最为常用的 `term` （词项）过滤器，
可以用它处理数字（numbers）、布尔值（Booleans）、日期（dates）以及文本（text）。

让我们通过下面一个例子，先对数字（过滤）进行说明。创建并索引一些产品，文档里有字段
`price` 和 `productID` （ `价格` 和 `产品ID` ）：

[source,js]
--------------------------------------------------
POST /my_store/products/_bulk
{ "index": { "_id": 1 }}
{ "price" : 10, "productID" : "XHDK-A-1293-#fJ3" }
{ "index": { "_id": 2 }}
{ "price" : 20, "productID" : "KDKE-B-9947-#kL5" }
{ "index": { "_id": 3 }}
{ "price" : 30, "productID" : "JODL-X-1937-#pV7" }
{ "index": { "_id": 4 }}
{ "price" : 30, "productID" : "QQPX-R-3956-#aD8" }
--------------------------------------------------
// SENSE: 080_Structured_Search/05_Term_number.json

我们想要做的是查找具有某个价格的所有产品，有
关系数据库背景的人肯定熟悉 SQL，如果我们
将其用 SQL 形式表达，会是下面这样：

[source,sql]
--------------------------------------------------
SELECT document
FROM   products
WHERE  price = 20
--------------------------------------------------

在 Elasticsearch 的查询表达式（query DSL）中，我们可以使用 `term` 过滤器达到相同的
目的。 `term` 过滤器会查找我们指定的精确值。作为
其本身， `term` 过滤器是简单的。它接受一个字段名以及我们希望查找的数值：

[source,js]
--------------------------------------------------
{
    "term" : {
        "price" : 20
    }
}
--------------------------------------------------

一般来说，当查找某个具体值时，我们不需要对查询进行评分，我们只需要包含或排除文档，所以我们将使用一个 `constant_score` 查询，
在一个不评分的模式下来执行 `term` 查询，即评分都是一样。

[source,js]
--------------------------------------------------
GET /my_store/products/_search
{
    "query" : {
        "constant_score" : { <1>
            "filter" : {
                "term" : { <2>
                    "price" : 20
                }
            }
        }
    }
}
--------------------------------------------------
// SENSE: 080_Structured_Search/05_Term_number.json

<1> 使用 `constant_score` 查询来转换 `term` 查询以进行过滤。
<2>  我们之前提过的 `term` 过滤器。

尝试执行这个查询，它的搜索结果正如我们
期望一样：只有 `2` 个文档作为结果返回（因为只有 `2` 个文档的 `price` 字段
是 `20` ）：

[source,json]
--------------------------------------------------
"hits" : [
    {
        "_index" : "my_store",
        "_type" :  "products",
        "_id" :    "2",
        "_score" : 1.0, <1>
        "_source" : {
          "price" :     20,
          "productID" : "KDKE-B-9947-#kL5"
        }
    }
]
--------------------------------------------------
<1> 因为 `term` 查询放在 `filter` 条件中，不会进行相关性评分计算，并对结果中所有文档都给予一个中性评分 `1` 。


==== 过滤文本

如本部分开始处提到过的一样 ((("structured search", "finding exact values", "using term filter with text")))
((("term filter", "with text")))，使用 `term` 过滤器匹配字符串
和匹配数字一样容易。如果我们想要查询某个具体 UPC ID 的产品，使用 SQL 表达式
会是如下这样：

[source,sql]
--------------------------------------------------
SELECT product
FROM   products
WHERE  productID = "XHDK-A-1293-#fJ3"
--------------------------------------------------

转换成查询表达式（query DSL），同样使用 `term` 过滤器，形式如下：

[source,js]
--------------------------------------------------
GET /my_store/products/_search
{
    "query" : {
        "constant_score" : {
            "filter" : {
                "term" : {
                    "productID" : "XHDK-A-1293-#fJ3"
                }
            }
        }
    }
}
--------------------------------------------------
// SENSE: 080_Structured_Search/05_Term_text.json

但这里有个小问题：我们无法获得期望的结果。为什么
呢？问题不在 `term` 查询，而在于
索引数据的方式。 ((("analyze API, using to understand tokenization"))) 如果我们使用 `analyze` （分析）API (<<analyze-api, 分析 API>>)，我们
可以看到这里的 UPC 码被拆分成多个小标记（token）：

[source,js]
--------------------------------------------------
GET /my_store/_analyze
{
  "field": "productID",
  "text": "XHDK-A-1293-#fJ3"
}
--------------------------------------------------
// SENSE: 080_Structured_Search/05_Term_text.json

[source,js]
--------------------------------------------------
{
  "tokens" : [ {
    "token" :        "xhdk",
    "start_offset" : 0,
    "end_offset" :   4,
    "type" :         "<ALPHANUM>",
    "position" :     1
  }, {
    "token" :        "a",
    "start_offset" : 5,
    "end_offset" :   6,
    "type" :         "<ALPHANUM>",
    "position" :     2
  }, {
    "token" :        "1293",
    "start_offset" : 7,
    "end_offset" :   11,
    "type" :         "<NUM>",
    "position" :     3
  }, {
    "token" :        "fj3",
    "start_offset" : 13,
    "end_offset" :   16,
    "type" :         "<ALPHANUM>",
    "position" :     4
  } ]
}
--------------------------------------------------
// SENSE: 080_Structured_Search/05_Term_text.json

这里有几点需要注意：

* Elasticsearch 用4个不同的标记（token）而不是单个标记（token）来表示这个UPC。
* 所有字母都是小写的。
* 丢失了连字符和哈希符（ `#` ）。

所以当我们用 `term` 过滤器去查找精确值 `XHDK-A-1293-#fJ3` 的时候，
找不到任何文档，因为它并不在我们的倒排索引（inverted index）中，
正如前面呈现出的分析结果，索引里有四个标记（tokens）。

显然这种对 ID 码或其他任何精确值的处理方式并不是我们想要的。

为了避免这种问题，我们需要告诉 Elasticsearch 该字段
具有精确值，要将其设置成 `not_analyzed` （未分析的）。((("not_analyzed string fields"))) 我们可以
在 <<custom-field-mappings, 自定义字段映射>> 中查看它的用法。为了修正搜索结果，我们需要首先删除
旧索引（因为它的映射不再正确）然后创建一个
能正确映射的新索引：

[source,js]
--------------------------------------------------
DELETE /my_store <1>

PUT /my_store <2>
{
    "mappings" : {
        "products" : {
            "properties" : {
                "productID" : {
                    "type" : "string",
                    "index" : "not_analyzed" <3>
                }
            }
        }
    }

}
--------------------------------------------------
// SENSE: 080_Structured_Search/05_Term_text.json
<1> 删除索引是必须的，因为我们不能更新已存在的映射。
<2> 在索引被删除后，我们可以创建新的索引并为其指定自定义映射。
<3> 这里我们告诉 Elasticsearch ，我们不想对 `productID` 做任何分析。

现在我们可以重新为文档进行索引：

[source,js]
--------------------------------------------------
POST /my_store/products/_bulk
{ "index": { "_id": 1 }}
{ "price" : 10, "productID" : "XHDK-A-1293-#fJ3" }
{ "index": { "_id": 2 }}
{ "price" : 20, "productID" : "KDKE-B-9947-#kL5" }
{ "index": { "_id": 3 }}
{ "price" : 30, "productID" : "JODL-X-1937-#pV7" }
{ "index": { "_id": 4 }}
{ "price" : 30, "productID" : "QQPX-R-3956-#aD8" }
--------------------------------------------------
// SENSE: 080_Structured_Search/05_Term_text.json

此时， `term` 过滤器就能搜索到我们想要的结果，让我们再次搜索
新索引过的数据（注意，查询和过滤并没有发生任何改变，改变的是
数据映射的方式）：

[source,js]
--------------------------------------------------
GET /my_store/products/_search
{
    "query" : {
        "constant_score" : {
            "filter" : {
                "term" : {
                    "productID" : "XHDK-A-1293-#fJ3"
                }
            }
        }
    }
}
--------------------------------------------------
// SENSE: 080_Structured_Search/05_Term_text.json

因为 `productID` 字段是未分析过的， `term` 过滤器不会对其做任何
分析，查询会进行精确查找并返回文档 1 。
成功！

[[_internal_filter_operation]]
==== 过滤器内部操作

在内部，Elasticsearch ((("structured search", "finding exact values", "intrnal filter operations")))
((("filters", "internal filter operation")))会在过滤的时候执行多个操作：

1. _查找匹配文档_ 。
+
`term` 过滤器在倒排索引中查找 `XHDK-A-1293-#fJ3`
然后获取包含该词项（term）的所有文档。本例中，
只有文档 1 满足我们要求。

2. _构建位集（bitset）_ 。
+
过滤器会创建一个 _位集（bitset）_ （一个包含 0 和 1 的数组），它
描述了哪个文档会包含该词项（term）。匹配文档的标志位是 1 。
本例中，位集的值为 `[1,0,0,0]` ，内部使用的是 https://www.elastic.co/blog/frame-of-reference-and-roaring-bitmaps["roaring bitmap"] ，对稀疏和密集的集合都能有效编码。

3. _迭代位集（bitset）_ 。
+
因为位集是按每次查询生成的，Elasticsearch 会对它们进行迭代来找到满足所有过滤条件的文档集合。
迭代的顺序也是启发探索式的，但是一般来说会先迭代最稀疏的位集（因为能排除最多的文档）。

4. _使用计算器自增（bitset）_ 。
+
Elasticsearch 可以缓存不需要评分的查询以便快速访问，但是不常用的查询如果也缓存就有点傻了。
非评分查询本来就已经很快了，所以我们是只希望缓存哪些以后还会被再次用到的查询来避免浪费资源。

要实现这个，Elasticsearch 会基于索引来跟踪查询使用的历史信息。
Elasticsearch 会在内存里面保留常用的 256 个查询，当位集被缓存之后，文档数少于 10,000 的段文件（小于总索引大小的3%）缓存会被自动忽略。
这些小段一般会倾向于很快消失，所以和缓存关联只会是浪费资源。

尽管事实上不一定是真的，但你可以理论上认为不用评分的查询要比需要评分的查询先执行，非评分查询的任务就是为了减少后面较耗资源的查询所需要参与的文档数量，从而产生比较快的查询。

在理论上意识到非评分查询会首先执行，你将编写出高效和快速的搜索请求。
